 /*
 * Distance estimation through stereo vision
 *
 * In default mode, the program first calibrates the camera and saves the data.
 * Then it uses the calibration information to undistort and rectify the
 * images. Using the resulting images, in real time, disparity map (calcuated
 * by block matching algorithm) is converted to a filtered depth map. In
 * addition, average (or min) distance values over sample areas are calcuated and
 * overlayed onto the retified map.
 *
 * Calibration step can be skipped by using precalibrated data.
 *
 * Note: Depth map is generated by four steps: undistortion, rectification,
 * correspondence, conversion.
 *
 * quick start: ./distance_demo -i stereocalib_demo.yml
 *
 * Author: William Xie, Abeer Javed
 */

#include <opencv2/core/core.hpp>
#include <opencv2/calib3d/calib3d.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/contrib/contrib.hpp>
#include <opencv2/gpu/gpu.hpp>
#include <stdio.h>
#include <stdint.h>
#include <math.h>
#include <sys/time.h>
#include <iostream>
#include <thread>
#include <mutex>
#include <string>

//#define BOOST
//#define NO_GUI
#define MAC
#define DEMO
#define FAST_CALIBRATION

#ifdef BOOST
#include <boost/asio.hpp>
#include "archive/SimpleSerial.hpp"
#endif /* BOOST */

/*
 * Distance between the centers of the two cameras
 */
#ifdef MAC
#define BASELINE_CM 5
#else
#define BASELINE_CM 5.4
#endif /* MAC */
#define UPPERVIBRATIONLIMIT 40000

/*
 * Camera ID, changes depending on the system
 * Will's mac: left = 0, right = 2
 * Pandaboard/NUC: left = 0, right = 1
 */
#ifdef MAC
#define CAMERA_LEFT_ID 0
#define CAMERA_RIGHT_ID 2
#else
#define CAMERA_LEFT_ID 0
#define CAMERA_RIGHT_ID 1
#endif /* MAC */

/*
 * Camera Picture Size (aspect ratio must be maintained)
 * Logitech C310 (default: 1280 × 720)
 */
#ifdef MAC
#define CAM_HEIGHT 640/2
#define CAM_WIDTH  480/2
#else
#define CAM_HEIGHT 640/2
#define CAM_WIDTH  480/2
#endif /* MAC */

/*
 * Calibration variables
 */
const char *calibration_file_name = "stereocalib.yml";
#define CALIBRATION_PAUSE_FRAME 0
#define CALIBRATION_SHOTS 1
#define CAL_FRAME_DELAY_MS 1000
#define BOARD_WIDTH 8
#define BOARD_LENGTH 6

/* Sampling box dimensions = SAMPLE_MULTI * SADWindowSize */
#define SAMPLE_MULTI_X 5
#define SAMPLE_MULTI_Y 5

#ifdef MAC
#define MAX_DISTANCE_CM 500
#define MIN_DISTANCE_CM 50
#else
#define MAX_DISTANCE_CM 450
#define MIN_DISTANCE_CM 50
#endif /* Mac */

/* Frame rate */
#define NUM_FRAMES_AVG 10

// Save session data flag (images, Q matrix)
#define SAVE_DATA 0

/*
 * String to specify actual block matching algorithm
 * (Semi-Global: SGBM, Global: BM)
 */
const cv::string method("SGBM");

using namespace cv;
using namespace std;

//typedef void handler_t(int);

static void help();
void create_sample_process();
void sample(VideoCapture cap_left, VideoCapture cap_right);
void test_camera_streams();
void calibrate_cameras(int num_boards, const char* file_name);
int load_calibration_info(const char* input_file);
void stream_disparity_map();
//handler_t * Signal(int signum, handler_t *handler);
void end_child();
void sigint_handler(int sig);
void close_devices();


/*
 * Variables used to undistort camera images
 */
Mat img_pair;
Mat img_left, img_right, map1x, map1y, map2x, map2y, CM1, CM2, D1, D2, R, T, E,
	F, R1, R2, P1, P2, Q, grey_left, grey_right, img_left_undistorted, img_right_undistorted;
int SADWindowSize, numberOfDisparities, preFilterSize, preFilterCap,
	minDisparity, textureThreshold, uniquenessRatio, speckleWindowSize,
	speckleRange, disp12MaxDiff, Pen1, Pen2;
bool  fullDP;

VideoCapture cap_left(CAMERA_LEFT_ID);
VideoCapture cap_right(CAMERA_RIGHT_ID);

int
main(int argc, char* argv[]) {
	int numBoards = CALIBRATION_SHOTS;
	char *input_file = NULL;
	bool precalibrated = false;
	/* Parse Command Line options */
	for (int i = 1; i < argc; i++) {
		char *s = argv[i];
		if (strcmp(s, "-n") == 0) {
			/* Set the numer of calibration shots */
			numBoards = atoi(argv[++i]);
		} else if (strcmp(s, "-i") == 0) {
			/* Skip the calibration process, instead load file */
			precalibrated = true;
			input_file = argv[++i];
		} else {
			help();
			return -1;
		}
	}

	/* Open camera capture devices */
	/*cap_left = VideoCapture();
	  const string filename0 = "/dev/v4l/by-id/usb-046d_081b_4A2F2A60-video-index0";
	  cap_left.open(filename0);
	  cap_right = VideoCapture();
	  const string filename1 = "/dev/v4l/by-id/usb-046d_081b_3CC27A60-video-index0";
	  cap_right.open(filename1);*/

	/* Resize capture images */
	cap_left.set(CV_CAP_PROP_FRAME_WIDTH, CAM_HEIGHT);
	cap_left.set(CV_CAP_PROP_FRAME_HEIGHT, CAM_WIDTH);
	cap_right.set(CV_CAP_PROP_FRAME_WIDTH, CAM_HEIGHT);
	cap_right.set(CV_CAP_PROP_FRAME_HEIGHT, CAM_WIDTH);

	/* Grab initial images */
	cap_left >> img_left;
	cap_right >> img_right;

	if (!precalibrated) {
		/* Test mode showing streams on screen */
		test_camera_streams();
		/* Calibrate cameras and save information in .yml file */
		calibrate_cameras(numBoards, calibration_file_name);
	}
	/* Load calibration information from .yml file */
	else if (load_calibration_info(input_file) == -1){
		exit(1);
	}

#ifdef DEMO
	test_camera_streams();
#endif /*end DEMO */

	/*
	 * Continuously calculate depth map, until user
	 * hits ESC
	 */
	stream_disparity_map();

	/*
	 * Prepare to end program by closing capture devices,
	 * killing child processes, and shutting image windows
	 */
	cout << "Cleaning up..." << endl;
	close_devices();
	destroyAllWindows();

	cout << "Goodbye" << endl;
	return (0);
}

void
close_devices()
{
	cap_left.release();
	cap_right.release();
}

static void
help()
{
	printf("\nUsage: distance\n"
	       "    [-n <num_board>]          # the number of calibration shots used for calibration\n"
	       "    [-i <input_file]          # calibration data for the camera setup\n"
	       "\n");
}

void
test_camera_streams()
{
	if (!cap_left.isOpened()){
		while(1);
	}
	printf("In test camera streaming mode.\n");
	printf("Hit space to start calibration...\n");
	while (1) {
		/* Get frames */
		//cap_left >> img_left;
		//cap_right >> img_right;
		cap_left.grab();
		cap_right.grab();
		cap_left.retrieve(img_left);
		cap_right.retrieve(img_right);

		/*
		 * Flip left image vertically and horizontally, to take into
		 * account of overlapping camera configuration
		 */
		flip(img_left, img_left, -1);

		/* Line up undistorted images with horizontal lines drawn for simpler alignment */
		Size sz1 = img_left.size();
		Size sz2 = img_right.size();
		img_pair = Mat(sz1.height, sz1.width + sz2.width, CV_8UC3);
		Mat left(img_pair, Rect(0, 0, sz1.width, sz1.height));
		img_left.copyTo(left);
		Mat right(img_pair, Rect(sz1.width, 0, sz2.width, sz2.height));
		img_right.copyTo(right);
		for (int i = 0; i < sz1.height; i += 50) {
			line(img_pair, Point(0, i), Point(sz1.width + sz2.width, i),
			     Scalar(144, 238, 144), 1, 8, 0);
		}

		imshow("Pair Images", img_pair);
		//		imshow("Left Camera", img_left);
		//		imshow("Right Camera", img_right);

		int c = cvWaitKey(40);

		/* Press space or escape to continue */
		if ((char)c == 32 || (char)c == 27) {
			break;
		}
	}
	destroyAllWindows();
}

void
calibrate_cameras(int num_boards, const char* file_name)
{
	vector<vector<Point3f> > object_points;
	vector<vector<Point2f> > imagePoints1, imagePoints2;
	vector<Point2f> corners1, corners2;
	vector<Point3f> obj;

	Mat gray_left, gray_right;
	int success = 0, k = 0, board_w = BOARD_WIDTH, board_h = BOARD_LENGTH,
		board_n = board_w * board_h;
	bool found_left = false, found_right = false;
	Size board_sz = Size(board_w, board_h);

	for (int j = 0; j < board_n; j++) {
		obj.push_back(Point3f(j/board_w, j%board_w, 0.0f));
	}

	while (success < num_boards) {
		/*
		 * Use grab() and retrieve() to reduce lag between each frame of the two
		 * cameras.
		 */
		cap_left.grab();
		cap_right.grab();
		cap_left.retrieve(img_left);
		cap_right.retrieve(img_right);

		/* left image is upside down */
		flip(img_left, img_left, -1);

		/* Find CHESSBOARD edges */
#ifndef FAST_CALIBRATION
		found_left = findChessboardCorners(img_left, board_sz, corners1,
						   CV_CALIB_CB_ADAPTIVE_THRESH | CV_CALIB_CB_FILTER_QUADS);
		found_right = findChessboardCorners(img_right, board_sz, corners2,
						    CV_CALIB_CB_ADAPTIVE_THRESH | CV_CALIB_CB_FILTER_QUADS);
#else
		/* Optional fast CHESSBOARD detection */
		found_left = findChessboardCorners(img_left, board_sz, corners1, CV_CALIB_CB_ADAPTIVE_THRESH | CV_CALIB_CB_FAST_CHECK | CV_CALIB_CB_NORMALIZE_IMAGE);
		found_right = findChessboardCorners(img_right, board_sz, corners2, CV_CALIB_CB_ADAPTIVE_THRESH | CV_CALIB_CB_FAST_CHECK | CV_CALIB_CB_NORMALIZE_IMAGE);
#endif

		/* Draw corners on original images if CHESSBOARD is detected. */
		if (found_left) {
			cvtColor(img_left, gray_left, CV_BGR2GRAY);
			cornerSubPix(gray_left, corners1, Size(11, 11), Size(-1, -1),
				     TermCriteria(CV_TERMCRIT_EPS | CV_TERMCRIT_ITER, 30, 0.1));
			drawChessboardCorners(img_left, board_sz, corners1, found_left);
		}
		if (found_right) {
			cvtColor(img_right, gray_right, CV_BGR2GRAY);
			cornerSubPix(gray_right, corners2, Size(11, 11), Size(-1, -1),
				     TermCriteria(CV_TERMCRIT_EPS | CV_TERMCRIT_ITER, 30, 0.1));
			drawChessboardCorners(img_right, board_sz, corners2, found_right);
		}

		/* Line up undistorted images with horizontal lines drawn for simpler alignment */
		Size sz1 = img_left.size();
		Size sz2 = img_right.size();
		img_pair = Mat(sz1.height, sz1.width + sz2.width, CV_8UC3);
		Mat left(img_pair, Rect(0, 0, sz1.width, sz1.height));
		img_left.copyTo(left);
		Mat right(img_pair, Rect(sz1.width, 0, sz2.width, sz2.height));
		img_right.copyTo(right);
		for (int i = 0; i < sz1.height; i += 50) {
			line(img_pair, Point(0, i), Point(sz1.width + sz2.width, i), Scalar(
											    144, 238, 144), 1, 8, 0);
		}

		imshow("Pair Image", img_pair);
		imshow("Left Camera", img_left);
		imshow("Right Camera", img_right);

		/* Gray out images to visually represent captured corners */
		if (found_left && found_right) {
			drawChessboardCorners(gray_left, board_sz, corners1, found_left);
			drawChessboardCorners(gray_right, board_sz, corners2, found_right);

			imshow("Left Camera", gray_left);
			imshow("Right Camera", gray_right);

			if (CALIBRATION_PAUSE_FRAME) {
				k = waitKey(0);
			} else {
				k = waitKey(CAL_FRAME_DELAY_MS);
			}
		} else {
			/*
			 *  The program waits for a finite time before attempting to get the next
			 *  frame for easier calibration.
			 */
			k = waitKey(CAL_FRAME_DELAY_MS);
		}

		/* Exit the loop if user presses ESC key */
		if (k == 27) {
			break;
		}

		/* Store the actual corners for calibration */
		if (found_left !=0 && found_right != 0) {
			imagePoints1.push_back(corners1);
			imagePoints2.push_back(corners2);
			object_points.push_back(obj);
			printf("Corners stored\n");
			success++;

			if (success >= num_boards) {
				break;
			}
		}
	}

	destroyAllWindows();

	/*
	 * If there's no input calibration info, compute it
	 * using data just collected
	 */
	printf("Starting Calibration.\n");
	CM1 = Mat(3, 3, CV_64FC1);
	CM2 = Mat(3, 3, CV_64FC1);

	stereoCalibrate(object_points, imagePoints1, imagePoints2, CM1, D1,
			CM2, D2, img_left.size(), R, T, E, F,
			cvTermCriteria(CV_TERMCRIT_ITER+CV_TERMCRIT_EPS, 100, 1e-5),
			CV_CALIB_SAME_FOCAL_LENGTH | CV_CALIB_ZERO_TANGENT_DIST);

	FileStorage fs1(file_name, FileStorage::WRITE);
	fs1 << "CM1" << CM1;
	fs1 << "CM2" << CM2;
	fs1 << "D1" << D1;
	fs1 << "D2" << D2;
	fs1 << "R" << R;
	fs1 << "T" << T;
	fs1 << "E" << E;
	fs1 << "F" << F;

	printf("Done Calibration\n");

	printf("Starting Rectification\n");

	stereoRectify(CM1, D1, CM2, D2, img_left.size(),
		      R, T, R1, R2, P1, P2, Q);
	fs1 << "R1" << R1;
	fs1 << "R2" << R2;
	fs1 << "P1" << P1;
	fs1 << "P2" << P2;
	fs1 << "Q" << Q;

	// Q.xml
	FileStorage fs2("Q.xml", FileStorage::WRITE);
	fs2 << "Q" << Q;

	fs1.release();
	fs2.release();

	printf("Done Rectification\n");


}

int
load_calibration_info(const char* input_file)
{
	/* Extract calibration data from .yml file */
	printf("Loading calibration variables...\n");
	FileStorage fs1(input_file, FileStorage::READ);
	if (!fs1.isOpened()) {
		cout << "Could not open calibration file \"" << input_file << "\""
		     << endl;
		return -1;
	}
	fs1["CM1"] >> CM1;
	fs1["CM2"] >> CM2;
	fs1["D1"] >> D1;
	fs1["D2"] >> D2;
	fs1["R"] >> R;
	fs1["T"] >> T;
	fs1["E"] >> E;
	fs1["F"] >> F;
	fs1["R1"] >> R1;
	fs1["R2"] >> R2;
	fs1["P1"] >> P1;
	fs1["P2"] >> P2;
	fs1["Q"] >> Q;
	fs1.release();
	printf("Finished loading pre-calibrated data.\n");

	return 0;
}


void
stream_disparity_map()
{
	Mat disparity_map, disparity_map_normalized, distance_normalized, display;
	int exitStream = 0;
	long d_sec, d_usec;
	double d_time;

	struct timeval total_start_time, total_current_time, begin_time, end_time;

	FILE* errorfile = fopen("berror", "w");

	int frame_counter = 0;
	double frame_delay = 0;

#ifdef BOOST
	/* Set up serial communication with Haptic module */
	SimpleSerial serial("/dev/ttyUSB0",115200);
#endif

	printf("Applying Undistort\n");

	initUndistortRectifyMap(CM1, D1, R1, P1, img_left.size(), CV_32FC1, map1x, map1y);
	initUndistortRectifyMap(CM2, D2, R2, P2, img_right.size(), CV_32FC1, map2x, map2y);

	/* Block match algorithm settings */
	if (!method.compare("BM")) {
		SADWindowSize = 9;
		numberOfDisparities = 112;
		preFilterSize = 5;
		preFilterCap = 61;
		minDisparity = -39;
		textureThreshold = 507;
		uniquenessRatio = 0;
		speckleWindowSize = 0;
		speckleRange = 8;
		disp12MaxDiff = 1;
	}
	if (!method.compare("SGBM")) {
		SADWindowSize = 5; /* Must be odd (default 7 x 7) */
		minDisparity = 0;  /* This should be >= 0 for horizontally aligned cam setup */
		/* Number of pixels you lose from the image, also the search range (min distance) */
		numberOfDisparities = 16 * 3; //values: 2-32 3-48 4-64 5-80
		/*
		 * Truncation value for the prefiltered image pixels. The algorithm first computes
		 * x-derivative at each pixel and clips its value by [-preFilterCap, preFilterCap]
		 * interval. The result values are passed to the Birchfield-Tomasi pixel cost function.
		 */
		preFilterCap = 63;
		/*
		 * Margin in percentage by which the best (minimum) computed cost function value
		 * should "win" the second best value to consider the found match correct.
		 * Normally, a value within the 5-15 range is good enough.
		 */
		uniquenessRatio = 10;
		/*
		 * Maximum size of smooth disparity regions to consider their noise speckles and
		 * invalidate. Set it to 0 to disable speckle filtering. Otherwise, set it
		 * somewhere in the 50-200 range.
		 */
		speckleWindowSize = 50;
		/* Maximum disparity variation within each connected component. If you do speckle
		 * filtering, set the parameter to a positive value, it will be implicitly
		 * multiplied by 16. Normally, 1 or 2 is good enough.
		 */
		speckleRange = 1;
		/*
		 * Maximum allowed difference (in integer pixel units) in the left-right disparity
		 * check. Set it to a non-positive value to disable the check.
		 */
		disp12MaxDiff = 1;
		/*
		 * Penalty values, P1 is the penalty on the disparity change by plus or minus
		 * 1 between neighbor pixels. P2 is the penalty on the disparity change by
		 * more than 1 between neighbor pixels.
		 * P2 > P1, higher the values, smoother the disparity.
		 * Good values: (
		 * 8  * number_of_image_channels * SADWindowSize * SADWindowSize,
		 * 32 * number_of_image_channels * SADWindowSize * SADWindowSize )
		 * Example values:
		 * sbm.P1 = 216;
		 * sbm.P2 = 864;
		 */
		Pen1 = 8 * 1 * SADWindowSize * SADWindowSize;
		Pen2 = 32 * 1 * SADWindowSize * SADWindowSize;
		/* Set it to true to run the full-scale two-pass dynamic programming algorithm. */
		fullDP = true;
	}

	gettimeofday(&total_start_time, NULL);

	FILE* battery_log;
	unsigned int time_counter = 60;
	system("rm /home/arcane/Desktop/distance/battery_log");

	printf("Streaming disparity map...\n");
	while (!exitStream) {
		cap_left.grab();
		cap_right.grab();
		cap_left.retrieve(img_left);
		cap_right.retrieve(img_right);

		flip(img_left, img_left, -1);

		/* Calculate frame rate */
		gettimeofday(&end_time, NULL);
		gettimeofday(&total_current_time, NULL);
#ifndef MAC
		if (total_current_time.tv_sec - total_start_time.tv_sec > time_counter){
			time_counter += 60;
			battery_log = fopen("/home/arcane/Desktop/distance/battery_log", "a");
			fprintf(battery_log, "Time elapsed (min): %lu\n", (total_current_time.tv_sec - total_start_time.tv_sec) / 60);
			fclose(battery_log);
		}
#endif /* MAC */
		d_sec = end_time.tv_sec - begin_time.tv_sec;
		d_usec = end_time.tv_usec - begin_time.tv_usec;
		d_time = (d_sec * pow(10, 6) + d_usec) / pow(10, 3);

		/* Add the latest frame delay to the the total */
		frame_delay += d_time;
		frame_counter++;

		if (frame_counter == NUM_FRAMES_AVG) {
			printf("Average frame rate: %.2f \t Number of frames: %d\n",
			       1000 / (frame_delay / NUM_FRAMES_AVG), NUM_FRAMES_AVG);
			frame_delay = 0;
			frame_counter = 0;
		}

		gettimeofday(&begin_time, NULL);

		/* Apply rectification data */
		remap(img_left, img_left_undistorted, map1x, map1y, INTER_LINEAR, BORDER_CONSTANT, Scalar());
		remap(img_right, img_right_undistorted, map2x, map2y, INTER_LINEAR, BORDER_CONSTANT, Scalar());
		img_left = img_left_undistorted;
		img_right = img_right_undistorted;

		/* Set images to gray scale for disparity calcuatlion */
		cvtColor(img_left, grey_left, CV_BGR2GRAY);
		cvtColor(img_right, grey_right, CV_BGR2GRAY);

		/* Calculate disparity map */
		if (!method.compare("BM")) {
			StereoBM sbm;
			sbm.state->SADWindowSize = SADWindowSize;
			sbm.state->numberOfDisparities = numberOfDisparities;
			sbm.state->preFilterSize = preFilterSize;
			sbm.state->preFilterCap = preFilterCap;
			sbm.state->minDisparity = minDisparity;
			sbm.state->textureThreshold = textureThreshold;
			sbm.state->uniquenessRatio = uniquenessRatio;
			sbm.state->speckleWindowSize = speckleWindowSize;
			sbm.state->speckleRange = speckleRange;
			sbm.state->disp12MaxDiff = disp12MaxDiff;
  			sbm(grey_left, grey_right, disparity_map, CV_16S);
		} else if (!method.compare("SGBM")) {
			StereoSGBM sbm;
			sbm.SADWindowSize = SADWindowSize;
			sbm.numberOfDisparities = numberOfDisparities;
			sbm.minDisparity = minDisparity;
			sbm.preFilterCap = preFilterCap;
			sbm.uniquenessRatio = uniquenessRatio;
			sbm.speckleWindowSize = speckleWindowSize;
			sbm.speckleRange = speckleRange;
			sbm.disp12MaxDiff = disp12MaxDiff;
			sbm.P1 = Pen1;
			sbm.P2 = Pen2;
			sbm.fullDP = fullDP;
			sbm(grey_left, grey_right, disparity_map);
		}

		/* Normalize the map for visualization */
		normalize(disparity_map, disparity_map_normalized, 0, 255, CV_MINMAX, CV_8UC3);

		/* Create pair rectified image */
		Size sz1 = img_left_undistorted.size();
		Size sz2 = img_right_undistorted.size();
		img_pair = Mat(sz1.height, sz1.width + sz2.width, CV_8UC3);
		Mat left(img_pair, Rect(0, 0, sz1.width, sz1.height));
		img_left_undistorted.copyTo(left);
		Mat right(img_pair, Rect(sz1.width, 0, sz2.width, sz2.height));
		img_right_undistorted.copyTo(right);
		for (int i = 0; i < sz1.height; i += 50) {
			line(img_pair, Point(0, i), Point(sz1.width + sz2.width, i),
			     Scalar(144, 238, 144), 1, 8, 0);
		}

		/* Get and print distance values at sampling points */
		/* Find the average focal length (pixel) by extracting focal x and y from calibration data */
		unsigned char *input = (unsigned char *)(CM1.data);
		double fx = ((double *)input)[0];
		double fy = ((double *)input)[4];
		double favg = (fx + fy) / 2;

		// Draw distance values on rectified left image
		display = img_left.clone();
		Size disp_size = img_left_undistorted.size();
		int pointIndex = 0;

		// TODO make it wider
		/* Outer loop for each sampling area */
		for (int y = disp_size.height / 6; y < disp_size.height; y += disp_size.height / 3) {
			/* Width takes into acount of the columns we 'lose' from pixel matching */
			for (int x = (disp_size.width - numberOfDisparities) / 8 + numberOfDisparities;
				 x < disp_size.width;
			     x += (disp_size.width - numberOfDisparities) * 3 / 4) {
/*
			for (int x = (disp_size.width - numberOfDisparities) / 4 + numberOfDisparities;
			     x < disp_size.width;
			     x += (disp_size.width - numberOfDisparities) / 2) {
*/
				double distance_min = MAX_DISTANCE_CM; /* Store the minimum value of current area*/
				string msg, msg2;

				double distance_avg = 0;
				int pixels_sampled = 0;

				/* Distance = focal_length * base_line / disparity */
				/* Find minimum in the area */

				for (int x_sam = x - (SADWindowSize * SAMPLE_MULTI_X / 2);
				     x_sam <= x + (SADWindowSize * SAMPLE_MULTI_X / 2);
				     x_sam += SADWindowSize) {
					for (int y_sam = y - (SADWindowSize * SAMPLE_MULTI_Y / 2);
					     y_sam <= y + (SADWindowSize * SAMPLE_MULTI_Y / 2);
					     y_sam += SADWindowSize) {
						double distance_val;
						/* Default disparity matrix value = dispairty (pixel) * 16 */
						float disparity_val = (float)disparity_map.at<short>(y_sam, x_sam)/(float)16;

						if (disparity_val < 0) {
							distance_val = 0;
						} else {
							/* Distance calcuation */
							distance_val = favg * BASELINE_CM
								/ disparity_val;
						}

						/* Apply correction to real distance values */
#ifdef MAC
						/* 5cm */
//						distance_val = 0.6116 * pow(distance_val, 1.2325);
						distance_val = 2.3115 * distance_val - 49.896; // Linear fit
#else
						/* box */
						distance_val = 18.619 * exp(0.0328 * distance_val);
#endif /* Mac */

//						cout <<distance_val << endl;
						if (distance_val > MIN_DISTANCE_CM && distance_val < MAX_DISTANCE_CM) {
							pixels_sampled++;
							distance_avg += distance_val;
						}


						/* Note that disparity is set to (minDisparity - 1) when in valid */
						/* Only use valid samples, filter negative and high disparity values */
						if (distance_val > 0 && distance_val < MAX_DISTANCE_CM) {

							/* Save the min value */
							if (distance_val < distance_min) {
								distance_min = distance_val;
							}
						}

						/* Mark the sampling points */
						circle(display, Point(x_sam, y_sam), 2, Scalar(0, 255, 0), -1, 8);
					}
				}

				/* Use min value if available; otherwise, -1 */
				if (distance_min >= MAX_DISTANCE_CM) {
					distance_min = -1;
				}

				/* Make sure that we have at least one valid sampling point and calculate the average */
				if (distance_avg > 0) {
					distance_avg = distance_avg / pixels_sampled;
				} else {
					distance_avg = MAX_DISTANCE_CM;
				}

#ifdef BOOST
				// Send points out via serial
				char successMessage[20];
				char failMessage[20];
				int feedback = (MAX_DISTANCE_CM - distance_avg) * UPPERVIBRATIONLIMIT / MAX_DISTANCE_CM;
				sprintf(successMessage, "s %d %d \n", feedback, pointIndex);
				sprintf(failMessage, "s %d %d \n", 0, pointIndex);
				try {
					fprintf(errorfile, "About to write to bluetooth port...\n");
					if (feedback > UPPERVIBRATIONLIMIT || feedback < 0) {
						/*
						 * Incorrect reading due to object being too close, too far,
						 * or only one camera can see the object
						 */
						serial.writeString(failMessage);
						fprintf(errorfile, "Success!\n");
					} else {
						serial.writeString(successMessage);
						fprintf(errorfile, "Success!\n");
					}
				} catch (boost::system::system_error& e) {
					cout << "Error: " << e.what() <<endl;
					//exit(1);
				}

#endif /* BOOST */
				/* Display -1 if distance_avg is invalid */
				if (distance_avg == MAX_DISTANCE_CM) {
					distance_avg = -1;
				}

				/* Print values on image */
				msg2 = format("%.1f", distance_avg);
				putText(display, msg2, Point(x - numberOfDisparities, y), 1, 2, Scalar(0, 0, 255),
						2, CV_AA);
				pointIndex += 1;
			}
		}
#ifndef NO_GUI
		/* Construct depth map from disparity map for visual visual purposes */
		/*		Mat distance(disp_size.height, disp_size.width, CV_16UC1);
				for (int y = 0; y < disp_size.height; y++) {
				for (int x = 0; x < disp_size.width; x++) {
				float disparity_val = (float)disparity_map.at<short>(y, x)/(float)16;
				double distance_val = favg * 8 / disparity_val;
				// Set cutoff range
				if (distance_val < 20)
				distance_val = 20;
				if (distance_val > 300)
				distance_val = 300;
				distance.at<short>(y, x) = (short)(distance_val);
				}
				}
				normalize(distance, distance_normalized, 0, 225, CV_MINMAX, CV_8U);
		*/

		/* Display all matrice */

		imshow("pair", img_pair);
		Mat bgr( disparity_map_normalized.size(), CV_8UC3, Scalar(0,0,0));
#ifdef MAC
		applyColorMap(disparity_map_normalized, bgr, COLORMAP_JET);
		imshow("disparity color", bgr);
#endif /* MAC */

		imshow("disparity", disparity_map_normalized);
		imshow("display", display);
#endif /* NO_GUI */

		/* Esc to save current frames and exit */
		int c = cvWaitKey(40);
		if ((char)c == 27) {
			//fclose(battery_log);
			exitStream = 1;

#ifdef BOOST
			printf("About to turn off all motors. \n");
			serial.writeString("s 0\r");
#endif
		}

		// Save data before exiting
		if (exitStream && SAVE_DATA) {
			vector<int> compression_params;
			compression_params.push_back(CV_IMWRITE_PXM_BINARY);
			compression_params.push_back(1);
			imwrite("img_left_undistorted.ppm", img_left_undistorted, compression_params);
			imwrite("img_right_undistorted.ppm", img_right_undistorted, compression_params);
			imwrite("disparity.pgm", disparity_map_normalized);
			FileStorage fss("disp.yml", FileStorage::WRITE);
			fss << "disp" << disparity_map;
			fss.release();
			FileStorage fss2("disparity_map_normalized.yml", FileStorage::WRITE);
			fss2 << "disparity_map_normalized" << disparity_map_normalized;
			fss2.release();
			FileStorage fss3("dist.yml", FileStorage::WRITE);
			fss3.release();
			printf("Saved session data\n");
		}
	}
}

/*
 * The last lines of this file configures the behavior of the "Tab" key in
 * emacs.  Emacs has a rudimentary understanding of C syntax and style.  In
 * particular, depressing the "Tab" key once at the start of a new line will
 * insert as many tabs and/or spaces as are needed for proper indentation.
 */

/* Local Variables: */
/* mode: c */
/* c-default-style: "bsd" */
/* c-basic-offset: 8 */
/* c-continued-statement-offset: 4 */
/* indent-tabs-mode: t */
/* End: */
